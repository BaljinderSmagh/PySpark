{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/18 18:54:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/18 18:54:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#initialize Spark Session\n",
    "\n",
    "spark=SparkSession.builder.appName('CustomerChurn').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+--------+------------------+---------+------------+\n",
      "|RowNumber|CustomerId| Surname|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|Complain|Satisfaction Score|Card Type|Point Earned|\n",
      "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+--------+------------------+---------+------------+\n",
      "|        1|  15634602|Hargrave|        619|   France|Female| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|       1|                 2|  DIAMOND|         464|\n",
      "|        2|  15647311|    Hill|        608|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|       1|                 3|  DIAMOND|         456|\n",
      "|        3|  15619304|    Onio|        502|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|       1|                 3|  DIAMOND|         377|\n",
      "|        4|  15701354|    Boni|        699|   France|Female| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|       0|                 5|     GOLD|         350|\n",
      "|        5|  15737888|Mitchell|        850|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|       0|                 5|     GOLD|         425|\n",
      "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+--------+------------------+---------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df=spark.read.csv('Customer-Churn-Records.csv',header=True,inferSchema=True)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RowNumber: integer (nullable = true)\n",
      " |-- CustomerId: integer (nullable = true)\n",
      " |-- Surname: string (nullable = true)\n",
      " |-- CreditScore: integer (nullable = true)\n",
      " |-- Geography: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tenure: integer (nullable = true)\n",
      " |-- Balance: double (nullable = true)\n",
      " |-- NumOfProducts: integer (nullable = true)\n",
      " |-- HasCrCard: integer (nullable = true)\n",
      " |-- IsActiveMember: integer (nullable = true)\n",
      " |-- EstimatedSalary: double (nullable = true)\n",
      " |-- Exited: integer (nullable = true)\n",
      " |-- Complain: integer (nullable = true)\n",
      " |-- Satisfaction Score: integer (nullable = true)\n",
      " |-- Card Type: string (nullable = true)\n",
      " |-- Point Earned: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-------+-----------+---------+------+---+------+-------+-------------+---------+--------------+---------------+------+--------+------------------+---------+------------+\n",
      "|RowNumber|CustomerId|Surname|CreditScore|Geography|Gender|Age|Tenure|Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|Complain|Satisfaction Score|Card Type|Point Earned|\n",
      "+---------+----------+-------+-----------+---------+------+---+------+-------+-------------+---------+--------------+---------------+------+--------+------------------+---------+------------+\n",
      "|        0|         0|      0|          0|        0|     0|  0|     0|      0|            0|        0|             0|              0|     0|       0|                 0|        0|           0|\n",
      "+---------+----------+-------+-----------+---------+------+---+------+-------+-------------+---------+--------------+---------------+------+--------+------------------+---------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,isnan,when,count\n",
    "\n",
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql.types import StringType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Surname', 'Geography', 'Gender', 'Card Type']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all categorical columns in a DataFrame\n",
    "categorical_cols = [field.name for field in df.schema.fields if field.dataType == StringType()]\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+---+------+---------+-------------+---------+--------------+---------------+------+--------+------------------+------------+-------------+---------------+------------+---------------+\n",
      "|RowNumber|CustomerId|CreditScore|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|Complain|Satisfaction Score|Point Earned|Surname_index|Geography_index|Gender_index|Card Type_index|\n",
      "+---------+----------+-----------+---+------+---------+-------------+---------+--------------+---------------+------+--------+------------------+------------+-------------+---------------+------------+---------------+\n",
      "|        1|  15634602|        619| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|       1|                 2|         464|       1958.0|            0.0|         1.0|            0.0|\n",
      "|        2|  15647311|        608| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|       1|                 3|         456|         79.0|            2.0|         1.0|            0.0|\n",
      "|        3|  15619304|        502| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|       1|                 3|         377|        336.0|            0.0|         1.0|            0.0|\n",
      "|        4|  15701354|        699| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|       0|                 5|         350|        128.0|            0.0|         1.0|            1.0|\n",
      "|        5|  15737888|        850| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|       0|                 5|         425|         32.0|            2.0|         1.0|            1.0|\n",
      "+---------+----------+-----------+---+------+---------+-------------+---------+--------------+---------------+------+--------+------------------+------------+-------------+---------------+------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Endcode the categorical columns\n",
    "indexers=[StringIndexer(inputCol=column,outputCol=column+'_index') for column\n",
    "          in\n",
    "          categorical_cols]\n",
    "# Sequentially apply each StringIndexer to the DataFrame\n",
    "for indexer in indexers:\n",
    "    df = indexer.fit(df).transform(df)\n",
    "# Drop the original categorical columns\n",
    "df=df.drop(*categorical_cols)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructField('RowNumber', IntegerType(), True),\n",
       " StructField('CustomerId', IntegerType(), True),\n",
       " StructField('CreditScore', IntegerType(), True),\n",
       " StructField('Age', IntegerType(), True),\n",
       " StructField('Tenure', IntegerType(), True),\n",
       " StructField('Balance', DoubleType(), True),\n",
       " StructField('NumOfProducts', IntegerType(), True),\n",
       " StructField('HasCrCard', IntegerType(), True),\n",
       " StructField('IsActiveMember', IntegerType(), True),\n",
       " StructField('EstimatedSalary', DoubleType(), True),\n",
       " StructField('Exited', IntegerType(), True),\n",
       " StructField('Complain', IntegerType(), True),\n",
       " StructField('Satisfaction Score', IntegerType(), True),\n",
       " StructField('Point Earned', IntegerType(), True),\n",
       " StructField('Surname_index', DoubleType(), False),\n",
       " StructField('Geography_index', DoubleType(), False),\n",
       " StructField('Gender_index', DoubleType(), False),\n",
       " StructField('Card Type_index', DoubleType(), False)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            features|Exited|\n",
      "+--------------------+------+\n",
      "|[619.0,42.0,2.0,0...|     1|\n",
      "|[608.0,41.0,1.0,8...|     0|\n",
      "|[502.0,42.0,8.0,1...|     1|\n",
      "|[699.0,39.0,1.0,0...|     0|\n",
      "|[850.0,43.0,2.0,1...|     0|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define the feature columns\n",
    "feature_cols=['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Complain','Satisfaction Score','Point Earned','Geography_index']\n",
    "\n",
    "#Assemble the feature vector\n",
    "assembler=VectorAssembler(inputCols=feature_cols,outputCol='features')\n",
    "df=assembler.transform(df)\n",
    "\n",
    "\n",
    "#final dataset\n",
    "final_df=df.select('features','Exited')\n",
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/18 19:35:40 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "#Train test split\n",
    "train_data,test_data=final_df.randomSplit([0.8,0.2],seed=42)\n",
    "\n",
    "#Intialize the Logistic Regression model\n",
    "lr=LogisticRegression(labelCol='Exited',featuresCol='features')\n",
    "\n",
    "#Train the model\n",
    "lr_model=lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+----------+\n",
      "|            features|Exited|prediction|\n",
      "+--------------------+------+----------+\n",
      "|(12,[0,1,4,7,9,10...|     0|       0.0|\n",
      "|(12,[0,1,4,7,9,10...|     0|       0.0|\n",
      "|(12,[0,1,4,7,9,10...|     0|       0.0|\n",
      "|[350.0,54.0,1.0,1...|     1|       1.0|\n",
      "|[365.0,30.0,0.0,1...|     1|       1.0|\n",
      "+--------------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Make predictions\n",
    "predictions=lr_model.transform(test_data)\n",
    "\n",
    "#show sample predictions\n",
    "predictions.select('features','Exited','prediction').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performace metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model AUC:  1.00\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator=BinaryClassificationEvaluator(labelCol='Exited',metricName='areaUnderROC')\n",
    "\n",
    "auc=evaluator.evaluate(predictions)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Model AUC:  {auc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
